{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd2176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tinker in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (0.2.2)\n",
      "Requirement already satisfied: transformers in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: dotenv in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (0.9.9)\n",
      "Requirement already satisfied: tinker-cookbook in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (0.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from tinker) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from tinker) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from httpx[http2]<1,>=0.23.0->tinker) (0.28.1)\n",
      "Requirement already satisfied: numpy in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from tinker) (2.3.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from tinker) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from tinker) (1.3.1)\n",
      "Requirement already satisfied: torch in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from tinker) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from tinker) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->tinker) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->httpx[http2]<1,>=0.23.0->tinker) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->httpx[http2]<1,>=0.23.0->tinker) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->httpx[http2]<1,>=0.23.0->tinker) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from httpx[http2]<1,>=0.23.0->tinker) (4.3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]<1,>=0.23.0->tinker) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]<1,>=0.23.0->tinker) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->tinker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->tinker) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->tinker) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: python-dotenv in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->tinker) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from jinja2->torch->tinker) (3.0.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: python-dotenv in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from torch->tinker) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->tinker) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages (from jinja2->torch->tinker) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tinker transformers dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fec8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinker\n",
    "from tinker import types\n",
    "import dotenv\n",
    "import os\n",
    "import json\n",
    "dotenv.load_dotenv()\n",
    "TINKER_API_KEY = os.getenv(\"TINKER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff3eacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tml-2b8sVND0ufiWAex6GjiPWgRR084MzYK8im8aXROUHIdJO3sj3oyG9cstvRz7laj3CAAAA'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TINKER_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb7a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "- deepseek-ai/DeepSeek-V3.1\n",
      "- deepseek-ai/DeepSeek-V3.1-Base\n",
      "- meta-llama/Llama-3.1-70B\n",
      "- meta-llama/Llama-3.1-8B\n",
      "- meta-llama/Llama-3.1-8B-Instruct\n",
      "- meta-llama/Llama-3.2-1B\n",
      "- meta-llama/Llama-3.2-3B\n",
      "- meta-llama/Llama-3.3-70B-Instruct\n",
      "- Qwen/Qwen3-235B-A22B-Instruct-2507\n",
      "- Qwen/Qwen3-30B-A3B\n",
      "- Qwen/Qwen3-30B-A3B-Base\n",
      "- Qwen/Qwen3-30B-A3B-Instruct-2507\n",
      "- Qwen/Qwen3-32B\n",
      "- Qwen/Qwen3-4B-Instruct-2507\n",
      "- Qwen/Qwen3-8B\n",
      "- Qwen/Qwen3-8B-Base\n",
      "- openai/gpt-oss-120b\n",
      "- openai/gpt-oss-20b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "service_client = tinker.ServiceClient(api_key=TINKER_API_KEY)\n",
    "print(\"Available models:\")\n",
    "for item in service_client.get_server_capabilities().supported_models:\n",
    "    print(\"- \" + item.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18511623",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"Qwen/Qwen3-30B-A3B-Instruct-2507\"\n",
    "training_client = service_client.create_lora_training_client(\n",
    "    base_model=base_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2eae6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhushanshah/Documents/ARC-AGI-2/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Get the tokenizer from the training client\n",
    "tokenizer = training_client.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879b6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prompts_path = os.path.join(\"../data/arc-agi-2025/prompts/arc-agi_training_prompts.json\")\n",
    "validation_prompts_path = os.path.join(\"../data/arc-agi-2025/prompts/arc-agi_validation_prompts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1fad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_prompts_path, 'r') as f:\n",
    "    training_prompts = json.load(f)\n",
    "\n",
    "with open(validation_prompts_path, 'r') as f:\n",
    "    validation_prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac8330bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 prompts...\n",
      "Processed 100 prompts...\n",
      "Processed 100 prompts...\n",
      "Processed 150 prompts...\n",
      "Processed 150 prompts...\n",
      "Processed 200 prompts...\n",
      "Processed 200 prompts...\n",
      "Processed 250 prompts...\n",
      "Processed 250 prompts...\n",
      "Processed 300 prompts...\n",
      "Processed 300 prompts...\n",
      "Processed 350 prompts...\n",
      "Processed 350 prompts...\n",
      "Processed 400 prompts...\n",
      "Processed 400 prompts...\n",
      "Processed 450 prompts...\n",
      "Processed 450 prompts...\n",
      "Processed 500 prompts...\n",
      "Processed 500 prompts...\n",
      "Processed 550 prompts...\n",
      "Processed 550 prompts...\n",
      "Processed 600 prompts...\n",
      "Processed 600 prompts...\n",
      "Processed 650 prompts...\n",
      "Processed 650 prompts...\n",
      "Processed 700 prompts...\n",
      "Processed 700 prompts...\n",
      "Processed 750 prompts...\n",
      "Processed 750 prompts...\n",
      "Processed 800 prompts...\n",
      "Processed 800 prompts...\n",
      "Processed 850 prompts...\n",
      "Processed 850 prompts...\n",
      "Processed 900 prompts...\n",
      "Processed 900 prompts...\n",
      "Processed 950 prompts...\n",
      "Processed 950 prompts...\n",
      "Processed 1000 prompts...\n",
      "Processed 1000 prompts...\n",
      "Processed 1050 prompts...\n",
      "Processed 1050 prompts...\n",
      "Processed 1100 prompts...\n",
      "Processed 1100 prompts...\n",
      "Processed 1150 prompts...\n",
      "Processed 1150 prompts...\n",
      "Processed 1200 prompts...\n",
      "Processed 1200 prompts...\n"
     ]
    }
   ],
   "source": [
    "prompt_lengths = []\n",
    "count = 0\n",
    "for prompt in training_prompts + validation_prompts:\n",
    "    input_ids = tokenizer.encode(prompt['prompt'] + prompt['output'])\n",
    "    prompt_lengths.append(len(input_ids))\n",
    "    count += 1\n",
    "    if count % 50 == 0:\n",
    "        print(f\"Processed {count} prompts...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16770eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(prompt_lengths, bins=50)\n",
    "plt.title(\"Distribution of Prompt Lengths\")\n",
    "plt.xlabel(\"Length (in tokens)\")\n",
    "plt.ylabel(\"Number of Prompts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856e19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    learning_rate = 1e-4\n",
    "    max_sequence_length = 32500\n",
    "    lora_rank = 32\n",
    "\n",
    "    def __init__(self, epochs=5, batch_size=64, learning_rate=1e-4, max_sequence_length=32500, lora_rank=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.lora_rank = lora_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f31d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(learning_rate=5e-4, batch_size=64, epochs=5, max_sequence_length=32500, lora_rank=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ecfc578",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_prompts = []\n",
    "new_validation_prompts = []\n",
    "for prompt in training_prompts:\n",
    "    input_ids = tokenizer.encode(prompt['prompt'] + prompt['output'])\n",
    "    if len(input_ids) <= config.max_sequence_length:\n",
    "        new_training_prompts.append(prompt)\n",
    "\n",
    "for prompt in validation_prompts:\n",
    "    input_ids = tokenizer.encode(prompt['prompt'] + prompt['output'])\n",
    "    if len(input_ids) <= config.max_sequence_length:\n",
    "        new_validation_prompts.append(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8847b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example: dict, tokenizer) -> types.Datum:\n",
    "    # Format the input with Input/Output template\n",
    "    # For most real use cases, you'll want to use a renderer / chat template,\n",
    "    # (see later docs) but here, we'll keep it simple.\n",
    "    prompt = example['prompt']\n",
    "    \n",
    "    prompt_tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    prompt_weights = [0] * len(prompt_tokens)\n",
    "    # Add a space before the output string, and finish with double newline\n",
    "    completion_tokens = tokenizer.encode(example['output'], add_special_tokens=False)\n",
    "    completion_weights = [1] * len(completion_tokens)\n",
    " \n",
    "    tokens = prompt_tokens + completion_tokens\n",
    "    weights = prompt_weights + completion_weights\n",
    " \n",
    "    input_tokens = tokens[:-1]\n",
    "    target_tokens = tokens[1:] # We're predicting the next token, so targets need to be shifted.\n",
    "    weights = weights[1:]\n",
    " \n",
    "    # A datum is a single training example for the loss function.\n",
    "    # It has model_input, which is the input sequence that'll be passed into the LLM,\n",
    "    # loss_fn_inputs, which is a dictionary of extra inputs used by the loss function.\n",
    "    return types.Datum(\n",
    "        model_input=types.ModelInput.from_ints(tokens=input_tokens),\n",
    "        loss_fn_inputs=dict(weights=weights, target_tokens=target_tokens)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d20e3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_training_examples = [process_example(ex, tokenizer) for ex in new_training_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e45f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_validation_examples = [process_example(ex, tokenizer) for ex in new_validation_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e58ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421d6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Appended synchronous training loop (paste/run after preprocessing cells)\n",
    "# import time\n",
    "# import math\n",
    "# import random\n",
    "# import os\n",
    "# import json\n",
    "# from typing import List, Iterator\n",
    "\n",
    "# # --- Safety checks ---\n",
    "# assert 'training_client' in globals(), \"training_client not found. Run the earlier cell that creates it.\"\n",
    "# assert 'processed_training_examples' in globals(), \"processed_training_examples not found. Run the preprocessing cell.\"\n",
    "# assert 'config' in globals(), \"config not found. Create or adjust Config in earlier cell.\"\n",
    "\n",
    "# # Small helper: batch generator\n",
    "# def batch_generator(examples: List[types.Datum], batch_size: int, shuffle: bool = True) -> Iterator[List[types.Datum]]:\n",
    "#     idxs = list(range(len(examples)))\n",
    "#     if shuffle:\n",
    "#         random.shuffle(idxs)\n",
    "#     for i in range(0, len(idxs), batch_size):\n",
    "#         batch_idx = idxs[i:i+batch_size]\n",
    "#         yield [examples[j] for j in batch_idx]\n",
    "\n",
    "# # collate: return the batch as-is. If your client needs padding, modify this.\n",
    "# def collate_batch(batch: List[types.Datum]) -> List[types.Datum]:\n",
    "#     return batch\n",
    "\n",
    "# # Training hyperparams from config\n",
    "# epochs = getattr(config, \"epochs\", 5)\n",
    "# batch_size = getattr(config, \"batch_size\", 64)\n",
    "# learning_rate = getattr(config, \"learning_rate\", 5e-4)\n",
    "# checkpoint_dir = \"./tinker_checkpoints\"\n",
    "# os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# # Logging helpers\n",
    "# def now():\n",
    "#     return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "# def save_checkpoint(step_num: int, metadata: dict = None):\n",
    "#     checkpoint_meta = {\n",
    "#         \"step\": step_num,\n",
    "#         \"timestamp\": now()\n",
    "#     }\n",
    "#     if metadata:\n",
    "#         checkpoint_meta.update(metadata)\n",
    "#     path = os.path.join(checkpoint_dir, f\"checkpoint_step_{step_num}.json\")\n",
    "#     with open(path, \"w\") as f:\n",
    "#         json.dump(checkpoint_meta, f)\n",
    "#     print(f\"[{now()}] Saved local checkpoint metadata -> {path}\")\n",
    "#     try:\n",
    "#         if hasattr(training_client, \"save_checkpoint\"):\n",
    "#             print(f\"[{now()}] Calling training_client.save_checkpoint(step={step_num})\")\n",
    "#             training_client.save_checkpoint(name=f\"checkpoint_step_{step_num}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"[{now()}] Warning: saving checkpoint to remote failed: {e}\")\n",
    "\n",
    "# # Main training loop (synchronous)\n",
    "# global_step = 0\n",
    "# print(f\"[{now()}] Starting training: epochs={epochs}, batch_size={batch_size}, lr={learning_rate}\")\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     epoch_start = time.time()\n",
    "#     epoch_loss_accum = 0.0\n",
    "#     epoch_items = 0\n",
    "#     batch_iter = batch_generator(processed_training_examples, batch_size, shuffle=True)\n",
    "#     for batch in batch_iter:\n",
    "#         global_step += 1\n",
    "#         batch = collate_batch(batch)\n",
    "#         try:\n",
    "#             fb_out = training_client.forward_backward(batch)\n",
    "#         except Exception as e:\n",
    "#             # small retry/backoff on transient errors\n",
    "#             print(f\"[{now()}] forward_backward failed at step {global_step}: {e}. Retrying once...\")\n",
    "#             try:\n",
    "#                 time.sleep(1.0)\n",
    "#                 fb_out = training_client.forward_backward(batch)\n",
    "#             except Exception as e2:\n",
    "#                 print(f\"[{now()}] Retry failed: {e2}. Skipping this batch.\")\n",
    "#                 continue\n",
    "\n",
    "#         # extract loss (attempt common keys)\n",
    "#         batch_loss = None\n",
    "#         try:\n",
    "#             if hasattr(fb_out, \"loss_fn_outputs\") and isinstance(fb_out.loss_fn_outputs, dict):\n",
    "#                 for k, v in fb_out.loss_fn_outputs.items():\n",
    "#                     if isinstance(v, (float, int)):\n",
    "#                         batch_loss = float(v)\n",
    "#                         break\n",
    "#             if batch_loss is None and hasattr(fb_out, \"output_diagnostics\"):\n",
    "#                 for k, v in fb_out.output_diagnostics.items():\n",
    "#                     if isinstance(v, (float, int)):\n",
    "#                         batch_loss = float(v)\n",
    "#                         break\n",
    "#         except Exception:\n",
    "#             batch_loss = None\n",
    "\n",
    "#         # Apply optimizer step\n",
    "#         try:\n",
    "#             if hasattr(training_client, \"optim_step\"):\n",
    "#                 training_client.optim_step(learning_rate)\n",
    "#             elif hasattr(training_client, \"step_optimizer\"):\n",
    "#                 training_client.step_optimizer(learning_rate)\n",
    "#             else:\n",
    "#                 print(f\"[{now()}] Warning: training_client has no known optim_step method; check docs.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"[{now()}] optim_step failed at step {global_step}: {e}\")\n",
    "\n",
    "#         # Logging\n",
    "#         if batch_loss is not None:\n",
    "#             epoch_loss_accum += batch_loss * len(batch)\n",
    "#             epoch_items += len(batch)\n",
    "#         if global_step % 10 == 0:\n",
    "#             avg_loss_so_far = (epoch_loss_accum / epoch_items) if epoch_items > 0 else None\n",
    "#             print(f\"[{now()}] Epoch {epoch} step {global_step}  avg_loss_so_far={avg_loss_so_far}\")\n",
    "\n",
    "#         # Periodic checkpointing\n",
    "#         if global_step % 200 == 0:\n",
    "#             save_checkpoint(global_step, metadata={\"epoch\": epoch, \"avg_loss_so_far\": (epoch_loss_accum / epoch_items) if epoch_items else None})\n",
    "\n",
    "#     # End of epoch\n",
    "#     epoch_time = time.time() - epoch_start\n",
    "#     epoch_avg_loss = (epoch_loss_accum / epoch_items) if epoch_items > 0 else None\n",
    "#     print(f\"[{now()}] Finished epoch {epoch}/{epochs}  time={epoch_time:.1f}s  avg_loss={epoch_avg_loss}\")\n",
    "\n",
    "#     # Save checkpoint per epoch\n",
    "#     save_checkpoint(global_step, metadata={\"epoch\": epoch})\n",
    "\n",
    "# print(f\"[{now()}] Training complete. Total steps: {global_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce4d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-24 01:36:37] Starting async training: epochs=5, batch_size=64, base_lr=0.0005\n",
      "[2025-10-24 01:44:53] Epoch 1 step 10  avg_loss_so_far=0.02339751615738133 lr=0.00044\n",
      "[2025-10-24 01:44:53] Epoch 1 step 10  avg_loss_so_far=0.02339751615738133 lr=0.00044\n",
      "[2025-10-24 01:48:25] Finished epoch 1/5 time=708.1s avg_loss=0.022281535429219453\n",
      "[2025-10-24 01:48:25] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_15.json\n",
      "[2025-10-24 01:48:25] Finished epoch 1/5 time=708.1s avg_loss=0.022281535429219453\n",
      "[2025-10-24 01:48:25] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_15.json\n",
      "[2025-10-24 01:54:08] Epoch 2 step 20  avg_loss_so_far=0.016910625513625342 lr=0.0003733333333333333\n",
      "[2025-10-24 01:54:08] Epoch 2 step 20  avg_loss_so_far=0.016910625513625342 lr=0.0003733333333333333\n",
      "[2025-10-24 02:07:21] Epoch 2 step 30  avg_loss_so_far=0.014629881821749926 lr=0.0003066666666666667\n",
      "[2025-10-24 02:07:21] Finished epoch 2/5 time=1135.5s avg_loss=0.014629881821749926\n",
      "[2025-10-24 02:07:21] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_30.json\n",
      "[2025-10-24 02:07:21] Epoch 2 step 30  avg_loss_so_far=0.014629881821749926 lr=0.0003066666666666667\n",
      "[2025-10-24 02:07:21] Finished epoch 2/5 time=1135.5s avg_loss=0.014629881821749926\n",
      "[2025-10-24 02:07:21] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_30.json\n",
      "[2025-10-24 02:13:20] Epoch 3 step 40  avg_loss_so_far=0.009889404130084385 lr=0.00024\n",
      "[2025-10-24 02:13:20] Epoch 3 step 40  avg_loss_so_far=0.009889404130084385 lr=0.00024\n",
      "[2025-10-24 02:18:08] Finished epoch 3/5 time=647.6s avg_loss=0.00989099830590519\n",
      "[2025-10-24 02:18:08] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_45.json\n",
      "[2025-10-24 02:18:08] Finished epoch 3/5 time=647.6s avg_loss=0.00989099830590519\n",
      "[2025-10-24 02:18:08] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_45.json\n",
      "[2025-10-24 02:22:06] Epoch 4 step 50  avg_loss_so_far=0.006634871532703812 lr=0.00017333333333333334\n",
      "[2025-10-24 02:22:06] Epoch 4 step 50  avg_loss_so_far=0.006634871532703812 lr=0.00017333333333333334\n",
      "[2025-10-24 02:28:31] Epoch 4 step 60  avg_loss_so_far=0.006051591242855182 lr=0.0001066666666666667\n",
      "[2025-10-24 02:28:31] Finished epoch 4/5 time=622.5s avg_loss=0.006051591242855182\n",
      "[2025-10-24 02:28:31] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_60.json\n",
      "[2025-10-24 02:28:31] Epoch 4 step 60  avg_loss_so_far=0.006051591242855182 lr=0.0001066666666666667\n",
      "[2025-10-24 02:28:31] Finished epoch 4/5 time=622.5s avg_loss=0.006051591242855182\n",
      "[2025-10-24 02:28:31] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_60.json\n",
      "[2025-10-24 02:35:11] Epoch 5 step 70  avg_loss_so_far=0.0034805689636966688 lr=3.999999999999998e-05\n",
      "[2025-10-24 02:35:11] Epoch 5 step 70  avg_loss_so_far=0.0034805689636966688 lr=3.999999999999998e-05\n",
      "[2025-10-24 02:39:10] Finished epoch 5/5 time=639.7s avg_loss=0.003509711649059723\n",
      "[2025-10-24 02:39:10] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_75.json\n",
      "[2025-10-24 02:39:10] Async training finished. Total steps: 75\n",
      "[2025-10-24 02:39:10] Finished epoch 5/5 time=639.7s avg_loss=0.003509711649059723\n",
      "[2025-10-24 02:39:10] Saved local checkpoint metadata -> ./tinker_checkpoints/checkpoint_step_75.json\n",
      "[2025-10-24 02:39:10] Async training finished. Total steps: 75\n"
     ]
    }
   ],
   "source": [
    "# Clean async training loop (improved/standalone). Paste/run after setup cells.\n",
    "import asyncio\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Iterator\n",
    "\n",
    "# Preconditions (these are created in earlier cells):\n",
    "assert 'training_client' in globals(), 'training_client not found. Run the earlier cell that creates it.'\n",
    "assert 'processed_training_examples' in globals(), 'processed_training_examples not found. Run preprocessing.'\n",
    "assert 'config' in globals(), 'config not found. Define or import Config.'\n",
    "\n",
    "def batch_generator(examples: List[types.Datum], batch_size: int, shuffle: bool = True) -> Iterator[List[types.Datum]]:\n",
    "    idxs = list(range(len(examples)))\n",
    "    if shuffle:\n",
    "        random.shuffle(idxs)\n",
    "    for i in range(0, len(idxs), batch_size):\n",
    "        yield [examples[j] for j in idxs[i:i+batch_size]]\n",
    "\n",
    "def collate_batch(batch: List[types.Datum]) -> List[types.Datum]:\n",
    "    # tinker typically accepts a list of Datum; pad here if your client requires tensors\n",
    "    return batch\n",
    "\n",
    "def compute_mean_nll(logprobs_list, weights_list):\n",
    "    total = 0.0\n",
    "    total_w = 0.0\n",
    "    for lp_seq, w_seq in zip(logprobs_list, weights_list):\n",
    "        # Handle TensorData or similar wrappers\n",
    "        if hasattr(lp_seq, 'tolist'):\n",
    "            lp_seq = lp_seq.tolist()\n",
    "        elif hasattr(lp_seq, 'to_numpy'):\n",
    "            lp_seq = lp_seq.to_numpy()\n",
    "\n",
    "        if hasattr(w_seq, 'tolist'):\n",
    "            w_seq = w_seq.tolist()\n",
    "        elif hasattr(w_seq, 'to_numpy'):\n",
    "            w_seq = w_seq.to_numpy()\n",
    "\n",
    "        lp = np.array(lp_seq, dtype=float)\n",
    "        w = np.array(w_seq, dtype=float)\n",
    "\n",
    "        # ensure equal length\n",
    "        if lp.shape != w.shape:\n",
    "            min_len = min(lp.shape[0], w.shape[0])\n",
    "            lp = lp[:min_len]\n",
    "            w = w[:min_len]\n",
    "\n",
    "        total += (-lp * w).sum()\n",
    "        total_w += w.sum()\n",
    "\n",
    "    return float(total / total_w) if total_w > 0 else None\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = getattr(config, 'epochs', 5)\n",
    "batch_size = getattr(config, 'batch_size', 64)\n",
    "base_lr = getattr(config, 'learning_rate', 5e-4)\n",
    "checkpoint_dir = './tinker_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def now():\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "\n",
    "def save_checkpoint(step_num: int, metadata: dict = None):\n",
    "    checkpoint_meta = {'step': step_num, 'timestamp': now()}\n",
    "    if metadata:\n",
    "        checkpoint_meta.update(metadata)\n",
    "    path = os.path.join(checkpoint_dir, f'checkpoint_step_{step_num}.json')\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(checkpoint_meta, f)\n",
    "    print(f'[{now()}] Saved local checkpoint metadata -> {path}')\n",
    "    try:\n",
    "        if hasattr(training_client, 'save_checkpoint'):\n",
    "            training_client.save_checkpoint(name=f'checkpoint_step_{step_num}')\n",
    "    except Exception as e:\n",
    "        print(f'[{now()}] Warning: remote checkpoint save failed: {e}')\n",
    "\n",
    "# Async wrappers that prefer the async client API and fall back to sync calls in executor\n",
    "async def call_forward_backward(batch):\n",
    "    if hasattr(training_client, 'forward_backward_async'):\n",
    "        maybe_coro = training_client.forward_backward_async(batch, loss_fn='cross_entropy')\n",
    "        res = await maybe_coro if asyncio.iscoroutine(maybe_coro) else maybe_coro\n",
    "        # handle future-like result objects returned by Tinker async APIs\n",
    "        if hasattr(res, 'result_async'):\n",
    "            return await res.result_async()\n",
    "        if hasattr(res, 'result'):\n",
    "            return res.result()\n",
    "        return res\n",
    "    else:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        return await loop.run_in_executor(None, training_client.forward_backward, batch)\n",
    "\n",
    "async def call_optim_step(adam_params):\n",
    "    if hasattr(training_client, 'optim_step_async'):\n",
    "        maybe_coro = training_client.optim_step_async(adam_params)\n",
    "        res = await maybe_coro if asyncio.iscoroutine(maybe_coro) else maybe_coro\n",
    "        if hasattr(res, 'result_async'):\n",
    "            return await res.result_async()\n",
    "        if hasattr(res, 'result'):\n",
    "            return res.result()\n",
    "        return res\n",
    "    else:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        return await loop.run_in_executor(None, training_client.optim_step, adam_params)\n",
    "\n",
    "async def train_async():\n",
    "    global_step = 0\n",
    "    num_examples = len(processed_training_examples)\n",
    "    steps_per_epoch = max(1, math.ceil(num_examples / batch_size))\n",
    "    print(f'[{now()}] Starting async training: epochs={epochs}, batch_size={batch_size}, base_lr={base_lr}')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        epoch_loss_accum = 0.0\n",
    "        epoch_items = 0\n",
    "        for batch in batch_generator(processed_training_examples, batch_size, shuffle=True):\n",
    "            global_step += 1\n",
    "            batch = collate_batch(batch)\n",
    "\n",
    "            # linear LR schedule\n",
    "            step = global_step - 1\n",
    "            lr_mult = max(0.0, 1.0 - step / (steps_per_epoch * epochs))\n",
    "            current_lr = base_lr * lr_mult\n",
    "            adam_params = tinker.AdamParams(learning_rate=current_lr, beta1=0.9, beta2=0.95, eps=1e-8)\n",
    "\n",
    "            # forward/backward (async-aware)\n",
    "            try:\n",
    "                fwd_res = await call_forward_backward(batch)\n",
    "            except Exception as e:\n",
    "                print(f'[{now()}] forward_backward failed at step {global_step}: {e}. Retrying once...')\n",
    "                try:\n",
    "                    await asyncio.sleep(1.0)\n",
    "                    fwd_res = await call_forward_backward(batch)\n",
    "                except Exception as e2:\n",
    "                    print(f'[{now()}] Retry failed: {e2}. Skipping this batch.')\n",
    "                    continue\n",
    "\n",
    "            # optimizer step\n",
    "            try:\n",
    "                _ = await call_optim_step(adam_params)\n",
    "            except Exception as e:\n",
    "                print(f'[{now()}] optim_step failed at step {global_step}: {e}')\n",
    "\n",
    "            # extract per-sequence logprobs following cookbook pattern\n",
    "            train_logprobs = []\n",
    "            try:\n",
    "                lf_outputs = getattr(fwd_res, 'loss_fn_outputs', None)\n",
    "                if isinstance(lf_outputs, list):\n",
    "                    for entry in lf_outputs:\n",
    "                        if isinstance(entry, dict) and 'logprobs' in entry:\n",
    "                            train_logprobs.append(entry['logprobs'])\n",
    "                elif isinstance(lf_outputs, dict) and 'logprobs' in lf_outputs:\n",
    "                    train_logprobs = [lf_outputs['logprobs']]\n",
    "                else:\n",
    "                    # debug print once if unexpected structure\n",
    "                    print(f'[{now()}] Unexpected loss_fn_outputs structure (truncated): {str(lf_outputs)[:400]}')\n",
    "            except Exception as e:\n",
    "                print(f'[{now()}] Could not extract loss_fn_outputs: {e}')\n",
    "\n",
    "            train_weights = [d.loss_fn_inputs['weights'] for d in batch]\n",
    "            train_nll = compute_mean_nll(train_logprobs, train_weights) if train_logprobs else None\n",
    "\n",
    "            if train_nll is not None:\n",
    "                epoch_loss_accum += train_nll * len(batch)\n",
    "                epoch_items += len(batch)\n",
    "\n",
    "            if global_step % 10 == 0:\n",
    "                avg_loss_so_far = (epoch_loss_accum / epoch_items) if epoch_items > 0 else None\n",
    "                print(f'[{now()}] Epoch {epoch} step {global_step}  avg_loss_so_far={avg_loss_so_far} lr={current_lr}')\n",
    "\n",
    "            if global_step % 200 == 0:\n",
    "                save_checkpoint(global_step, metadata={'epoch': epoch, 'avg_loss_so_far': (epoch_loss_accum / epoch_items) if epoch_items else None})\n",
    "\n",
    "        # end epoch\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        epoch_avg_loss = (epoch_loss_accum / epoch_items) if epoch_items > 0 else None\n",
    "        print(f'[{now()}] Finished epoch {epoch}/{epochs} time={epoch_time:.1f}s avg_loss={epoch_avg_loss}')\n",
    "        save_checkpoint(global_step, metadata={'epoch': epoch})\n",
    "\n",
    "    print(f'[{now()}] Async training finished. Total steps: {global_step}')\n",
    "\n",
    "# Run training. In Jupyter, top-level await works; otherwise use asyncio.run(train_async()).\n",
    "await train_async()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c5df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
